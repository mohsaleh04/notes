# فصل اول: کلیات تحقیق

## ۱-۱ مقدمه

در دهه‌های اخیر، رشد فزاینده جمعیت و توسعه شهرنشینی، مصرف انرژی در بخش ساختمان‌های مسکونی را به یکی از چالش‌های اصلی در مقیاس جهانی تبدیل کرده است. ساختمان‌ها به‌تنهایی مسئول بیش از ۳۰ درصد از مصرف کل انرژی جهانی هستند و در این میان، سیستم‌های گرمایش، تهویه و تهویه مطبوع (HVAC) نزدیک به ۴۰ درصد از این سهم را به خود اختصاص می‌دهند [1, 2]. این روند نه تنها بار مالی قابل توجهی را بر دوش خانوارها تحمیل می‌کند، بلکه پایداری شبکه‌های برق و تلاش‌ها برای کاهش اثرات زیست‌محیطی را نیز با چالش‌های جدی مواجه ساخته است [3].

در پاسخ به این چالش‌ها، ظهور فناوری‌های خانه هوشمند، که با بهره‌گیری از اینترنت اشیا (IoT)، سیستم‌های ذخیره‌سازی انرژی (ESS) و منابع انرژی تجدیدپذیر مانند پنل‌های خورشیدی همراه است، افق‌های جدیدی را برای مدیریت بهینه مصرف انرژی گشوده است [4, 5]. با این حال، مدیریت یکپارچه این منابع پیچیدگی‌های خاص خود را دارد. عدم قطعیت در تولید انرژی‌های تجدیدپذیر، نوسانات لحظه‌ای قیمت برق، تغییرات شرایط اقلیمی و الگوهای غیرقابل پیش‌بینی رفتار کاربران، سیستم‌های کنترلی سنتی را که اغلب مبتنی بر قوانین ثابت یا مدل‌های ریاضی دقیق هستند، ناکارآمد می‌سازد [6].

اینجاست که روش‌های یادگیری ماشین، به‌ویژه یادگیری تقویتی (Reinforcement Learning - RL)، به‌عنوان یک راهکار قدرتمند و انعطاف‌پذیر مطرح می‌شوند. الگوریتم‌های یادگیری تقویتی عمیق (Deep RL)، با قابلیت یادگیری مستقیم از طریق تعامل با محیط و بدون نیاز به مدل‌سازی صریح، می‌توانند در شرایط پویا و غیرقطعی، سیاست‌های کنترلی بهینه‌ای را بیاموزند. در میان این الگوریتم‌ها، DDPG (Deep Deterministic Policy Gradient) به دلیل توانایی مدیریت فضاهای عمل پیوسته، برای کنترل همزمان و دقیق منابعی مانند HVAC و ESS بسیار مناسب است [7]. پژوهش حاضر با الهام از موفقیت‌های اخیر در این حوزه و با هدف رفع کاستی‌های موجود، به طراحی و پیاده‌سازی یک عامل هوشمند مبتنی بر الگوریتم DDPG می‌پردازد تا بتواند مدیریت انرژی را در یک خانه هوشمند به‌صورت یکپارچه، بهینه و هوشمند به انجام رساند.

## ۲-۱ بیان مسئله

افزایش مصرف انرژی در بخش مسکونی و ضرورت گذار به سمت منابع انرژی پاک، نیاز به سیستم‌های مدیریت انرژی خانگی (HEMS) را بیش از پیش نمایان کرده است. یک خانه هوشمند مدرن، اکوسیستم پیچیده‌ای از منابع تولید (مانند پنل‌های خورشیدی)، منابع ذخیره‌سازی (ESS) و بارهای مصرفی متنوع (مانند HVAC و پمپ آب) است. مدیریت بهینه این اکوسیستم با چالش‌های متعددی روبروست: ۱. **عدم قطعیت و پویایی محیط:** تولید انرژی خورشیدی به شرایط آب‌وهوایی وابسته است، قیمت برق در طول روز نوسان می‌کند و الگوی مصرف ساکنان قابل پیش‌بینی نیست. ۲. **تضاد بین اهداف:** اهداف مدیریتی اغلب با یکدیگر در تضاد هستند. برای مثال، کاهش حداکثری هزینه انرژی ممکن است به کاهش سطح آسایش حرارتی کاربران منجر شود، یا استفاده مکرر از باتری برای بهینه‌سازی هزینه، عمر مفید آن را کاهش دهد. ۳. **پیچیدگی کنترل همزمان:** کنترل هماهنگ و همزمان چندین منبع انرژی که بر یکدیگر تأثیر متقابل دارند، نیازمند یک سیاست تصمیم‌گیری یکپارچه و هوشمند است.

روش‌های کنترلی سنتی، مانند کنترل مبتنی بر قاعده (Rule-Based) یا کنترل پیش‌بین مدل (MPC)، در مواجهه با این پیچیدگی‌ها دچار ضعف هستند. این روش‌ها یا بیش از حد ساده و ناکارآمدند و یا به مدل‌های ریاضی دقیقی از محیط نیاز دارند که تهیه آن‌ها دشوار و پرهزینه است [9]. در مقابل، الگوریتم‌های یادگیری تقویتی مدل-آزاد (Model-Free RL) مانند DDPG، با یادگیری از تجربیات گذشته، می‌توانند خود را با شرایط متغیر تطبیق داده و سیاست‌های کنترلی بهینه‌ای را برای مدیریت این سیستم پیچیده بیاموزند. با این حال، طراحی یک عامل RL که بتواند به‌طور مؤثر چندین منبع انرژی را با اهداف متضاد مدیریت کند، همچنان یک مسئله باز و نیازمند تحقیق است. این پژوهش دقیقاً بر این شکاف تمرکز دارد و به دنبال ارائه یک راهکار جامع مبتنی بر DDPG برای مدیریت هوشمند و یکپارچه انرژی در خانه‌های مسکونی است.

## ۳-۱ اهداف تحقیق

این پژوهش با هدف توسعه یک سیستم مدیریت انرژی هوشمند و کارآمد، مجموعه‌ای از اهداف علمی و کاربردی را دنبال می‌کند:

### ۱-۳-۱ اهداف علمی

- **طراحی یک مدل جامع یادگیری تقویتی:** توسعه یک چارچوب مبتنی بر الگوریتم DDPG برای کنترل همزمان و یکپارچه منابع انرژی چندگانه شامل HVAC، ESS و پمپ آب در یک خانه هوشمند.
    
- **مدل‌سازی محیط در قالب فرآیند تصمیم‌گیری مارکوف (MDP):** تعریف دقیق و مؤثر فضاهای حالت، عمل و تابع پاداش به‌گونه‌ای که اهداف متضاد (هزینه، آسایش و پایداری) را در بر گیرد و عامل را به سمت سیاست بهینه هدایت کند.
    
- **تحلیل و بهینه‌سازی هایپرپارامترها:** بررسی تأثیر هایپرپارامترهای کلیدی الگوریتم DDPG بر پایداری و سرعت همگرایی مدل و دستیابی به بهترین تنظیمات برای مسئله مورد نظر.
    
- **ارزیابی عملکرد و مقایسه تطبیقی:** سنجش کمی و کیفی عملکرد مدل نهایی در مقایسه با حالت پایه (پیش از بهینه‌سازی) و نتایج پژوهش‌های مرجع معتبر.
    

### ۲-۳-۱ اهداف کاربردی

- **کاهش هزینه‌های مصرف انرژی:** آموزش عاملی که بتواند با تطبیق الگوی مصرف با نوسانات قیمت برق و بهره‌گیری از منابع تجدیدپذیر، هزینه نهایی انرژی را برای خانوارها کاهش دهد.
    
- **حفظ و بهبود آسایش حرارتی:** اطمینان از اینکه دمای داخل ساختمان همواره در محدوده آسایش تعریف‌شده برای کاربران باقی می‌ماند.
    
- **افزایش بهره‌وری و طول عمر تجهیزات:** مدیریت بهینه چرخه‌های شارژ و دشارژ باتری (ESS) و کنترل روشن/خاموش شدن پمپ آب برای جلوگیری از استهلاک زودرس.
    
- **ارائه یک راهکار بومی‌سازی‌شده:** طراحی مدلی که قابلیت تطبیق با شرایط اقلیمی، الگوهای مصرف و تعرفه‌های برق در ایران را داشته باشد.
    

## ۴-۱ سؤالات و فرضیات تحقیق

برای دستیابی به اهداف فوق، این پژوهش به دنبال پاسخگویی به یک سؤال اصلی و چندین زیرسؤال مرتبط است.

**سؤال اصلی تحقیق:** چگونه می‌توان یک عامل هوشمند مبتنی بر یادگیری تقویتی عمیق (DDPG) را طراحی و آموزش داد تا بتواند مدیریت یکپارچه و بهینه‌ی منابع انرژی چندگانه (شامل HVAC، ESS و پمپ آب) را در یک خانه هوشمند، با در نظر گرفتن عدم قطعیت‌های محیطی و نوسانات قیمت برق، به انجام رساند؟

**زیرسؤالات تحقیق:** ۱. چگونه می‌توان دینامیک پیچیده منابع انرژی (HVAC، ESS، پمپ آب) و متغیرهای محیطی (دما، قیمت برق، تولید خورشیدی) را در قالب یک فرآیند تصمیم‌گیری مارکوف (MDP) با فضاهای حالت، عمل و تابع پاداش مناسب برای آموزش یک عامل DRL مدل‌سازی کرد؟ ۲. سیاست کنترلی بهینه‌ای که عامل یادگیرنده اتخاذ می‌کند، چگونه می‌تواند بین اهداف متضاد مانند کاهش هزینه انرژی، حفظ آسایش حرارتی کاربران و افزایش طول عمر تجهیزات، تعادل برقرار کند؟ ۳. عملکرد مدل DDPG بهینه‌شده در مقایسه با حالت پایه و سایر رویکردهای مرجع تا چه حد بهبود می‌یابد و پایداری آن در مواجهه با نویز و شرایط غیرقطعی محیط واقعی چگونه است؟

**فرضیات تحقیق:**

- **فرضیه اول:** الگوریتم DDPG قادر است بدون نیاز به مدل فیزیکی دقیق، سیاست کنترلی مؤثری برای مدیریت همزمان HVAC، ESS و پمپ آب بیاموزد.
    
- **فرضیه دوم:** طراحی یک تابع پاداش چندهدفه و بهینه‌سازی دقیق هایپرپارامترها، منجر به بهبود پایداری فرآیند یادگیری و دستیابی به عملکرد برتر در مقایسه با تنظیمات استاندارد می‌شود.
    
- **فرضیه سوم:** مدل نهایی قادر خواهد بود هزینه کل انرژی را به‌طور معناداری کاهش دهد، در حالی که سطح آسایش حرارتی کاربران را در محدوده مطلوب حفظ می‌کند.
    

## ۵-۱ نوآوری‌های تحقیق

این پژوهش در چندین جنبه دارای نوآوری است:

- **مدیریت یکپارچه منابع چندگانه:** برخلاف بسیاری از تحقیقات پیشین که بر یک یا دو منبع متمرکز بوده‌اند، این پژوهش برای اولین بار کنترل همزمان و هماهنگ سه جزء کلیدی (HVAC، ESS و پمپ آب) را با استفاده از یک عامل DRL واحد مورد بررسی قرار می‌دهد.
    
- **طراحی تابع پاداش جامع:** تابع پاداش طراحی‌شده در این مدل، به‌طور همزمان اهداف اقتصادی (هزینه)، آسایشی (دما) و فنی (طول عمر تجهیزات) را در نظر می‌گیرد تا یک سیاست کنترلی متوازن حاصل شود.
    
- **بهینه‌سازی تجربی و دقیق:** فرآیند بهینه‌سازی هایپرپارامترها در این تحقیق به‌صورت سیستماتیک و با تحلیل نتایج عملی انجام شده که به دستیابی به عملکردی پایدار و قابل اتکا منجر شده است.
    

## ۶-۱ ساختار پایان‌نامه

این پایان‌نامه در پنج فصل سازماندهی شده است. **فصل اول** به معرفی کلیات، اهداف و سؤالات تحقیق پرداخت. **فصل دوم** به مرور جامع ادبیات موضوع و بررسی پژوهش‌های پیشین در زمینه مدیریت انرژی هوشمند و کاربردهای یادگیری تقویتی اختصاص دارد. در **فصل سوم**، روش‌شناسی تحقیق، شامل معماری الگوریتم DDPG، نحوه مدل‌سازی محیط، تعریف فضاهای حالت، عمل و پاداش و فرآیند بهینه‌سازی هایپرپارامترها به‌تفصیل تشریح می‌شود. **فصل چهارم** به ارائه و تحلیل نتایج کمی و کیفی حاصل از اجرای مدل‌های اولیه و نهایی و مقایسه آن‌ها با یکدیگر و با پژوهش‌های مرجع می‌پردازد. در نهایت، **فصل پنجم** شامل جمع‌بندی نهایی، نتیجه‌گیری، ارائه پیشنهادهایی برای تحقیقات آتی و بیان محدودیت‌های پژوهش خواهد بود.



-----------------

# فصل اول: کلیات تحقیق

## ۱-۱ مقدمه

در دهه‌های اخیر، رشد فزاینده جمعیت و توسعه شهرنشینی، مصرف انرژی در بخش ساختمان‌های مسکونی را به یکی از چالش‌های اصلی در مقیاس جهانی تبدیل کرده است. این مسئله از دو جنبه حائز اهمیت است: از یک سو، افزایش تقاضا برای انرژی فشار بی‌سابقه‌ای بر منابع محدود و زیرساخت‌های تولید و توزیع وارد می‌کند و از سوی دیگر، پیامدهای زیست‌محیطی ناشی از مصرف سوخت‌های فسیلی، ضرورت گذار به سمت راهکارهای پایدار را دوچندان کرده است. ساختمان‌ها به‌تنهایی مسئول بیش از ۳۰ درصد از مصرف کل انرژی جهانی هستند و در این میان، سیستم‌های گرمایش، تهویه و تهویه مطبوع (HVAC) نزدیک به ۴۰ درصد از این سهم را به خود اختصاص می‌دهają [1, 2]. این روند نه تنها بار مالی قابل توجهی را بر دوش خانوارها تحمیل می‌کند، بلکه پایداری شبکه‌های برق و تلاش‌ها برای کاهش اثرات زیست‌محیطی را نیز با چالش‌های جدی مواجه ساخته است [3].

در پاسخ به این چالش‌ها، ظهور فناوری‌های خانه هوشمند، که با بهره‌گیری از اینترنت اشیا (IoT)، سیستم‌های ذخیره‌سازی انرژی (ESS) و منابع انرژی تجدیدپذیر مانند پنل‌های خورشیدی همراه است، افق‌های جدیدی را برای مدیریت بهینه مصرف انرژی گشوده است [4, 5]. یک خانه هوشمند مدرن، در واقع یک اکوسیستم پیچیده و پویاست که در آن دستگاه‌های مختلف به‌طور مداوم با یکدیگر و با محیط در تعامل هستند. با این حال، مدیریت یکپارچه این منابع پیچیدگی‌های خاص خود را دارد. عدم قطعیت در تولید انرژی‌های تجدیدپذیر، نوسانات لحظه‌ای قیمت برق، تغییرات شرایط اقلیمی و الگوهای غیرقابل پیش‌بینی رفتار کاربران، سیستم‌های کنترلی سنتی را که اغلب مبتنی بر قوانین ثابت یا مدل‌های ریاضی دقیق هستند، ناکارآمد می‌سازد [6].

اینجاست که روش‌های یادگیری ماشین، به‌ویژه یادگیری تقویتی (Reinforcement Learning - RL)، به‌عنوان یک راهکار قدرتمند و انعطاف‌پذیر مطرح می‌شوند. الگوریتم‌های یادگیری تقویتی عمیق (Deep RL)، با قابلیت یادگیری مستقیم از طریق تعامل با محیط و بدون نیاز به مدل‌سازی صریح، می‌توانند در شرایط پویا و غیرقطعی، سیاست‌های کنترلی بهینه‌ای را بیاموزند. در میان این الگوریتم‌ها، DDPG (Deep Deterministic Policy Gradient) به دلیل توانایی مدیریت فضاهای عمل پیوسته، برای کنترل همزمان و دقیق منابعی مانند HVAC و ESS بسیار مناسب است [7]. پژوهش حاضر با الهام از موفقیت‌های اخیر در این حوزه و با هدف رفع کاستی‌های موجود، به طراحی و پیاده‌سازی یک عامل هوشمند مبتنی بر الگوریتم DDPG می‌پردازد تا بتواند مدیریت انرژی را در یک خانه هوشمند به‌صورت یکپارچه، بهینه و هوشمند به انجام رساند.

## ۲-۱ بیان مسئله

افزایش مصرف انرژی در بخش مسکونی و ضرورت گذار به سمت منابع انرژی پاک، نیاز به سیستم‌های مدیریت انرژی خانگی (HEMS) را بیش از پیش نمایان کرده است. یک خانه هوشمند مدرن، اکوسیستم پیچیده‌ای از منابع تولید (مانند پنل‌های خورشیدی)، منابع ذخیره‌سازی (ESS) و بارهای مصرفی متنوع (مانند HVAC و پمپ آب) است. مدیریت بهینه این اکوسیستم با چالش‌های متعددی روبروست:

۱. **عدم قطعیت و پویایی محیط:** تولید انرژی خورشیدی به شرایط آب‌وهوایی وابسته است، قیمت برق در طول روز نوسان می‌کند و الگوی مصرف ساکنان قابل پیش‌بینی نیست. این پویایی مداوم، اتخاذ تصمیمات ایستا را غیرممکن می‌سازد و نیازمند یک سیستم کنترلی است که بتواند به‌صورت بلادرنگ خود را با تغییرات وفق دهد.

۲. **تضاد بین اهداف:** اهداف مدیریتی اغلب با یکدیگر در تضاد هستند. برای مثال، در یک بعدازظهر گرم تابستان که قیمت برق در اوج خود قرار دارد، هدف حفظ دمای خنک داخل خانه (مثلاً ۲۲ درجه سانتی‌گراد) با هدف به حداقل رساندن هزینه انرژی در تضاد مستقیم است. یک سیستم ساده ممکن است نتواند تعادل بهینه را بیابد، در حالی که یک عامل هوشمند می‌تواند با یادگیری الگوها، خانه را در ساعات ارزان‌تر پیش-سرمایش کند. به طور مشابه، استفاده مکرر از باتری برای بهینه‌سازی هزینه، عمر مفید آن را کاهش می‌دهد و این خود یک مصالحه (Trade-off) دیگر را به سیستم تحمیل می‌کند.

۳. **پیچیدگی کنترل همزمان:** کنترل هماهنگ و همزمان چندین منبع انرژی که بر یکدیگر تأثیر متقابل دارند، نیازمند یک سیاست تصمیم‌گیری یکپارچه و هوشمند است. تصمیم برای شارژ باتری با انرژی خورشیدی، بر میزان انرژی موجود برای سیستم HVAC و همچنین میزان فروش برق به شبکه تأثیر می‌گذارد. این وابستگی متقابل، ابعاد فضای تصمیم‌گیری را به‌شدت افزایش می‌دهد.

روش‌های کنترلی سنتی، مانند کنترل مبتنی بر قاعده (Rule-Based) یا کنترل پیش‌بین مدل (MPC)، در مواجهه با این پیچیدگی‌ها دچار ضعف هستند. این روش‌ها یا بیش از حد ساده و ناکارآمدند و یا به مدل‌های ریاضی دقیقی از محیط نیاز دارند که تهیه آن‌ها دشوار، پرهزینه و اغلب در برابر تغییرات محیطی شکننده است [9]. در مقابل، الگوریتم‌های یادگیری تقویتی مدل-آزاد (Model-Free RL) مانند DDPG، با یادگیری از تجربیات گذشته، می‌توانند خود را با شرایط متغیر تطبیق داده و سیاست‌های کنترلی بهینه‌ای را برای مدیریت این سیستم پیچیده بیاموزند. با این حال، طراحی یک عامل RL که بتواند به‌طور مؤثر چندین منبع انرژی را با اهداف متضاد مدیریت کند، همچنان یک مسئله باز و نیازمند تحقیق است. این پژوهش دقیقاً بر این شکاف تمرکز دارد و به دنبال ارائه یک راهکار جامع مبتنی بر DDPG برای مدیریت هوشمند و یکپارچه انرژی در خانه‌های مسکونی است.

## ۳-۱ اهداف تحقیق

این پژوهش با هدف توسعه یک سیستم مدیریت انرژی هوشمند و کارآمد، مجموعه‌ای از اهداف علمی و کاربردی را دنبال می‌کند:

### ۱-۳-۱ اهداف علمی

- **طراحی یک مدل جامع یادگیری تقویتی:** توسعه یک چارچوب مبتنی بر الگوریتم DDPG برای کنترل همزمان و یکپارچه منابع انرژی چندگانه شامل HVAC، ESS و پمپ آب در یک خانه هوشمند. این هدف، توانایی الگوریتم‌های DRL را در حل مسائل پیچیده و چندبعدی در حوزه انرژی به چالش می‌کشد.
    
- **مدل‌سازی محیط در قالب فرآیند تصمیم‌گیری مارکوف (MDP):** تعریف دقیق و مؤثر فضاهای حالت، عمل و تابع پاداش به‌گونه‌ای که اهداف متضاد (هزینه، آسایش و پایداری) را در بر گیرد و عامل را به سمت سیاست بهینه هدایت کند. این مدل‌سازی، یک گام بنیادی در ترجمه یک مسئله فیزیکی به یک چارچوب قابل حل برای هوش مصنوعی است.
    
- **تحلیل و بهینه‌سازی هایپرپارامترها:** بررسی تأثیر هایپرپارامترهای کلیدی الگوریتم DDPG (مانند نرخ یادگیری و فاکتور تخفیف) بر پایداری و سرعت همگرایی مدل و دستیابی به بهترین تنظیمات برای مسئله مورد نظر. این تحلیل به درک عمیق‌تری از رفتار الگوریتم در کاربردهای عملی کمک می‌کند.
    
- **ارزیابی عملکرد و مقایسه تطبیقی:** سنجش کمی و کیفی عملکرد مدل نهایی در مقایسه با حالت پایه (پیش از بهینه‌سازی) و نتایج پژوهش‌های مرجع معتبر، به منظور اعتبارسنجی علمی دستاوردهای تحقیق.
    

### ۲-۳-۱ اهداف کاربردی

- **کاهش هزینه‌های مصرف انرژی:** آموزش عاملی که بتواند با تطبیق الگوی مصرف با نوسانات قیمت برق و بهره‌گیری از منابع تجدیدپذیر، هزینه نهایی انرژی را برای خانوارها کاهش دهد. این هدف علاوه بر منفعت اقتصادی برای مصرف‌کننده، به مدیریت سمت تقاضا و کاهش فشار بر شبکه سراسری برق در ساعات اوج مصرف کمک می‌کند.
    
- **حفظ و بهبود آسایش حرارتی:** اطمینان از اینکه دمای داخل ساختمان همواره در محدوده آسایش تعریف‌شده برای کاربران باقی می‌ماند، که یکی از پیش‌نیازهای اساسی برای پذیرش فناوری‌های هوشمند توسط کاربران است.
    
- **افزایش بهره‌وری و طول عمر تجهیزات:** مدیریت بهینه چرخه‌های شارژ و دشارژ باتری (ESS) و کنترل روشن/خاموش شدن پمپ آب برای جلوگیری از استهلاک زودرس و هزینه‌های تعمیر و نگهداری آتی.
    
- **ارائه یک راهکار بومی‌سازی‌شده:** طراحی مدلی که قابلیت تطبیق با شرایط اقلیمی، الگوهای مصرف و ساختار تعرفه‌های پلکانی برق در ایران را داشته باشد و بتواند به‌عنوان یک الگوی عملی مورد استفاده قرار گیرد.
    

## ۴-۱ سؤالات و فرضیات تحقیق

برای دستیابی به اهداف فوق، این پژوهش به دنبال پاسخگویی به یک سؤال اصلی و چندین زیرسؤال مرتبط است که مسیر تحقیق را مشخص می‌کنند.

**سؤال اصلی تحقیق:** چگونه می‌توان یک عامل هوشمند مبتنی بر یادگیری تقویتی عمیق (DDPG) را طراحی و آموزش داد تا بتواند مدیریت یکپارچه و بهینه‌ی منابع انرژی چندگانه (شامل HVAC، ESS و پمپ آب) را در یک خانه هوشمند، با در نظر گرفتن عدم قطعیت‌های محیطی و نوسانات قیمت برق، به انجام رساند؟

**زیرسؤالات تحقیق:** ۱. چگونه می‌توان دینامیک پیچیده منابع انرژی (HVAC، ESS، پمپ آب) و متغیرهای محیطی (دما، قیمت برق، تولید خورشیدی) را در قالب یک فرآیند تصمیم‌گیری مارکوف (MDP) با فضاهای حالت، عمل و تابع پاداش مناسب برای آموزش یک عامل DRL مدل‌سازی کرد؟ ۲. سیاست کنترلی بهینه‌ای که عامل یادگیرنده اتخاذ می‌کند، چگونه می‌تواند بین اهداف متضاد مانند کاهش هزینه انرژی، حفظ آسایش حرارتی کاربران و افزایش طول عمر تجهیزات، تعادل برقرار کند؟ این سؤال به قلب تصمیم‌گیری هوشمندانه می‌پردازد و توانایی عامل را برای یافتن راه‌حل‌های بهینه در یک فضای چندهدفی بررسی می‌کند. ۳. عملکرد مدل DDPG بهینه‌شده در مقایسه با حالت پایه و سایر رویکردهای مرجع تا چه حد بهبود می‌یابد و پایداری آن در مواجهه با نویز و شرایط غیرقطعی محیط واقعی چگونه است؟

**فرضیات تحقیق:**

- **فرضیه اول:** الگوریتم DDPG قادر است بدون نیاز به مدل فیزیکی دقیق، سیاست کنترلی مؤثری برای مدیریت همزمان HVAC، ESS و پمپ آب بیاموزد و هماهنگی لازم بین آن‌ها را برقرار سازد.
    
- **فرضیه دوم:** طراحی یک تابع پاداش چندهدفه و بهینه‌سازی دقیق هایپرپارامترها، منجر به بهبود پایداری فرآیند یادگیری و دستیابی به عملکرد برتر در مقایسه با تنظیمات استاندارد می‌شود.
    
- **فرضیه سوم:** مدل نهایی قادر خواهد بود هزینه کل انرژی را به‌طور معناداری (بیش از ۲۰٪) کاهش دهد، در حالی که سطح آسایش حرارتی کاربران را در محدوده مطلوب (بیش از ۹۵٪ مواقع) حفظ می‌کند.
    

## ۵-۱ نوآوری‌های تحقیق

این پژوهش در چندین جنبه دارای نوآوری است که آن را از مطالعات پیشین متمایز می‌کند:

- **مدیریت یکپارچه منابع چندگانه:** برخلاف بسیاری از تحقیقات پیشین که بر یک یا دو منبع متمرکز بوده‌اند، این پژوهش برای اولین بار کنترل همزمان و هماهنگ سه جزء کلیدی (HVAC، ESS و پمپ آب) را با استفاده از یک عامل DRL واحد مورد بررسی قرار می‌دهد. گنجاندن پمپ آب به‌عنوان یک بار قابل کنترل، یک نوآوری مهم است، زیرا مصرف آن به‌ویژه در مناطقی با فشار آب نامنظم، قابل توجه بوده و اغلب در مطالعات HEMS نادیده گرفته می‌شود.
    
- **طراحی تابع پاداش جامع:** تابع پاداش طراحی‌شده در این مدل، به‌طور همزمان اهداف اقتصادی (هزینه)، آسایشی (دما) و فنی (طول عمر تجهیزات) را در نظر می‌گیرد تا یک سیاست کنترلی متوازن حاصل شود. این رویکرد جامع، به یادگیری سیاست‌هایی منجر می‌شود که در دنیای واقعی کاربردی‌تر و قابل‌پذیرش‌تر هستند.
    
- **بهینه‌سازی تجربی و دقیق:** فرآیند بهینه‌سازی هایپرپارامترها در این تحقیق به‌صورت سیستماتیک و با تحلیل نتایج عملی انجام شده که به دستیابی به عملکردی پایدار و قابل اتکا منجر شده است. این رویکرد عملی، برخلاف اتکای صرف به مقادیر تئوریک، اعتبار مدل را برای کاربردهای واقعی افزایش می‌دهد.
    

## ۶-۱ ساختار پایان‌نامه

این پایان‌نامه در پنج فصل سازماندهی شده است تا به‌طور منسجم مراحل مختلف تحقیق را پوشش دهد. **فصل اول** به معرفی کلیات، اهمیت مسئله، اهداف و سؤالات تحقیق پرداخت. **فصل دوم** یک مرور جامع بر ادبیات موضوع ارائه می‌دهد و ضمن بررسی پژوهش‌های پیشین در زمینه مدیریت انرژی هوشمند و کاربردهای یادگیری تقویتی، شکاف‌های تحقیقاتی موجود را شناسایی می‌کند. در **فصل سوم**، روش‌شناسی تحقیق به‌تفصیل تشریح می‌شود؛ این فصل شامل معماری الگوریتم DDPG، نحوه مدل‌سازی محیط، تعریف دقیق فضاهای حالت، عمل و پاداش و همچنین فرآیند بهینه‌سازی هایپرپارامترها است. **فصل چهارم** به ارائه و تحلیل نتایج کمی و کیفی اختصاص دارد. در این فصل، عملکرد مدل‌های اولیه و نهایی از طریق نمودارها و شاخص‌های آماری به نمایش گذاشته شده و با یکدیگر و با پژوهش‌های مرجع مقایسه می‌شوند. در نهایت، **فصل پنجم** شامل جمع‌بندی نهایی یافته‌ها، پاسخ به سؤالات تحقیق، ارائه پیشنهادهایی برای تحقیقات آتی و بیان محدودیت‌های پژوهش خواهد بود.